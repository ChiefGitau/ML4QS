{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Ball Trajectory Prediction Video Overlay\n",
    "- **LSTM predicted ball trajectory** (3 seconds into future)\n",
    "- **Actual ball position** for comparison\n",
    "- **Prediction accuracy visualization**\n",
    "- **Real-time error metrics**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "##  Load LSTM Model and Data"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Import LSTM model architecture\n",
    "from tennis_lstm import TennisLSTMModel, TennisLSTMAligned\n",
    "from tennis_utils import read_video, MiniCourt\n",
    "from create_tennis_video_overlay import TennisVideoOverlayCreator\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load the trained LSTM model\n",
    "print(\"📂 Loading LSTM model...\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize LSTM model with paper specifications\n",
    "model = TennisLSTMModel(\n",
    "    input_size=69,      # 69 features per frame\n",
    "    lstm1_units=128,    # First LSTM layer\n",
    "    lstm2_units=64,     # Second LSTM layer\n",
    "    dropout_rate=0.2\n",
    ").to(device)\n",
    "\n",
    "# Try to load the trained model weights\n",
    "model_files = [\n",
    "    'tennis_lstm_final_model.pth',\n",
    "    'best_lstm_model.pth'\n",
    "]\n",
    "\n",
    "model_loaded = False\n",
    "for model_file in model_files:\n",
    "    if os.path.exists(model_file):\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(model_file, map_location=device))\n",
    "            model.eval()\n",
    "            model_loaded = True\n",
    "            print(f\"LSTM model loaded from: {model_file}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"⚠Error loading {model_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "if not model_loaded:\n",
    "    print(\"No trained LSTM model found. Creating demo model with random weights.\")\n",
    "\n",
    "\n",
    "print(f\" LSTM layers: {model.lstm1.hidden_size} → {model.lstm2.hidden_size} units\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Load Tennis Data"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Load ball tracking data\n",
    "ball_data_file = \"ball_tracking.csv\"\n",
    "if os.path.exists(ball_data_file):\n",
    "    df_ball = pd.read_csv(ball_data_file)\n",
    "    print(f\" Ball data loaded: {len(df_ball)} records\")\n",
    "else:\n",
    "    print(f\" Ball tracking file not found: {ball_data_file}\")\n",
    "    df_ball = pd.DataFrame()\n",
    "\n",
    "player_data_file = \"player_tracking.csv\"\n",
    "if os.path.exists(player_data_file):\n",
    "    df_players = pd.read_csv(player_data_file)\n",
    "    print(f\" Player data loaded: {len(df_players)} records\")\n",
    "else:\n",
    "    print(f\" Player tracking file not found: {player_data_file}\")\n",
    "    df_players = pd.DataFrame()\n",
    "\n",
    "# Check data availability\n",
    "if len(df_ball) > 0:\n",
    "    print(f\"\\n Ball Data Summary:\")\n",
    "    print(f\"Videos: {df_ball['video_name'].nunique()}\")\n",
    "    print(f\" Total frames: {len(df_ball)}\")\n",
    "    print(f\"Valid detections: {(~df_ball['center_x'].isna()).sum()}\")\n",
    "    print(f\"mDetection rate: {(~df_ball['center_x'].isna()).mean():.1%}\")\n",
    "    \n",
    "    # Show sample videos\n",
    "    print(f\"\\nAvailable videos:\")\n",
    "    for i, video in enumerate(df_ball['video_name'].unique()[:5]):\n",
    "        video_ball_count = len(df_ball[df_ball['video_name'] == video])\n",
    "        video_detections = (~df_ball[df_ball['video_name'] == video]['center_x'].isna()).sum()\n",
    "        print(f\"   {i+1}. {video}: {video_detections}/{video_ball_count} ball detections\")\n",
    "    \n",
    "    if len(df_ball['video_name'].unique()) > 5:\n",
    "        print(f\" {len(df_ball['video_name'].unique()) - 5} more videos\")\n",
    "else:\n",
    "    print(\"No ball data available for prediction\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Create LSTM Prediction Pipeline"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class TennisLSTMPredictor:\n",
    "    \"\"\"\n",
    "    Real-time tennis ball trajectory predictor using LSTM\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, device='cpu'):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.scaler = StandardScaler()\n",
    "        self.sequence_length = 12  # Input frames\n",
    "        self.prediction_frames = 5  # Output frames\n",
    "        self.features_per_frame = 69\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def create_features(self, df_ball, df_players=None):\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        df_features = df_ball.copy()\n",
    "        \n",
    "        # Ensure required columns exist\n",
    "        if 'court_width_pixels' not in df_features.columns:\n",
    "            df_features['court_width_pixels'] = 1344.0\n",
    "        if 'court_height_pixels' not in df_features.columns:\n",
    "            df_features['court_height_pixels'] = 756.0\n",
    "        \n",
    "        # Add player positions if available\n",
    "        if df_players is not None and len(df_players) > 0:\n",
    "            # Get player 1 positions\n",
    "            player1 = df_players[df_players['player_id'] == 1].groupby(['video_name', 'frame_number']).first()\n",
    "            player1 = player1.reset_index()[['video_name', 'frame_number', 'center_x', 'center_y']]\n",
    "            player1.columns = ['video_name', 'frame_number', 'player_1_center_x', 'player_1_center_y']\n",
    "            \n",
    "            df_features = df_features.merge(player1, on=['video_name', 'frame_number'], how='left')\n",
    "\n",
    "        if 'player_1_center_x' not in df_features.columns:\n",
    "            df_features['player_1_center_x'] = 500.0\n",
    "        if 'player_1_center_y' not in df_features.columns:\n",
    "            df_features['player_1_center_y'] = 400.0\n",
    "        \n",
    "        df_features['player_1_center_x'] = df_features['player_1_center_x'].fillna(500.0)\n",
    "        df_features['player_1_center_y'] = df_features['player_1_center_y'].fillna(400.0)\n",
    "        \n",
    "        # Create time differential\n",
    "        df_features = df_features.sort_values(['video_name', 'frame_number'])\n",
    "        df_features['time_seconds'] = df_features['frame_number'] / 30.0\n",
    "        \n",
    "        # Calculate features by video\n",
    "        enhanced_dfs = []\n",
    "        \n",
    "        for video_name in df_features['video_name'].unique():\n",
    "            video_df = df_features[df_features['video_name'] == video_name].copy()\n",
    "            \n",
    "            if len(video_df) < self.sequence_length + self.prediction_frames:\n",
    "                continue  # Skip videos that are too short\n",
    "            \n",
    "            # Time differential\n",
    "            time_diff = video_df['time_seconds'].diff().replace(0, 0.0333).fillna(0.0333)\n",
    "            \n",
    "            # Court-relative positions\n",
    "            video_df['rel_x'] = video_df['center_x'] / video_df['court_width_pixels']\n",
    "            video_df['rel_y'] = video_df['center_y'] / video_df['court_height_pixels']\n",
    "            \n",
    "            # Velocity components\n",
    "            video_df['vx'] = video_df['center_x'].diff() / time_diff\n",
    "            video_df['vy'] = video_df['center_y'].diff() / time_diff\n",
    "            \n",
    "            # Convert to m/s\n",
    "            pixels_per_meter = 100\n",
    "            video_df['vx_ms'] = video_df['vx'] / pixels_per_meter\n",
    "            video_df['vy_ms'] = video_df['vy'] / pixels_per_meter\n",
    "            \n",
    "            # Speed and acceleration\n",
    "            video_df['speed'] = np.sqrt(video_df['vx']**2 + video_df['vy']**2)\n",
    "            video_df['speed_ms'] = np.sqrt(video_df['vx_ms']**2 + video_df['vy_ms']**2)\n",
    "            video_df['acceleration'] = np.sqrt(video_df['vx'].diff()**2 + video_df['vy'].diff()**2) / time_diff\n",
    "            \n",
    "            # Direction change\n",
    "            video_df['direction_change'] = np.arctan2(video_df['vy'], video_df['vx']).diff()\n",
    "            \n",
    "            # Player distance\n",
    "            video_df['player_dist'] = np.sqrt(\n",
    "                (video_df['player_1_center_x'] - video_df['center_x'])**2 + \n",
    "                (video_df['player_1_center_y'] - video_df['center_y'])**2\n",
    "            )\n",
    "            \n",
    "            # Base variables for additional features\n",
    "            base_vars = ['rel_x', 'rel_y', 'vx', 'vy', 'speed', 'acceleration', 'direction_change', 'player_dist']\n",
    "            \n",
    "            # Moving averages (16 features: 8 vars × 2 windows)\n",
    "            for var in base_vars:\n",
    "                video_df[f'{var}_ma3'] = video_df[var].rolling(3, min_periods=1).mean()\n",
    "                video_df[f'{var}_ma5'] = video_df[var].rolling(5, min_periods=1).mean()\n",
    "            \n",
    "\n",
    "            for var in base_vars:\n",
    "                video_df[f'{var}_std5'] = video_df[var].rolling(5, min_periods=1).std().fillna(0)\n",
    "            \n",
    "            # Court zone features (2 features)\n",
    "            video_df['near_net'] = ((video_df['rel_x'] > 0.4) & (video_df['rel_x'] < 0.6)).astype(int)\n",
    "            video_df['in_corner'] = ((video_df['rel_y'] < 0.2) | (video_df['rel_y'] > 0.8)).astype(int)\n",
    "            \n",
    "            # Additional features to reach 69 total\n",
    "            video_df['serve_rally_state'] = ((video_df['speed_ms'] > 15) & (video_df['rel_y'] < 0.5)).astype(int)\n",
    "            video_df['trajectory_curvature'] = np.abs(video_df['direction_change']).fillna(0)\n",
    "            video_df['vx_vy_ratio'] = np.abs(video_df['vx'] / (video_df['vy'] + 1e-6))\n",
    "            video_df['speed_change'] = video_df['speed'].diff().fillna(0)\n",
    "            video_df['distance_to_net'] = np.abs(video_df['rel_x'] - 0.5)\n",
    "            video_df['distance_to_baseline'] = np.minimum(video_df['rel_y'], 1 - video_df['rel_y'])\n",
    "            video_df['distance_to_sideline'] = np.minimum(video_df['rel_x'], 1 - video_df['rel_x'])\n",
    "            video_df['frame_number_norm'] = (video_df['frame_number'] - video_df['frame_number'].min()) / len(video_df)\n",
    "            video_df['time_in_rally'] = video_df['time_seconds'] - video_df['time_seconds'].iloc[0]\n",
    "            \n",
    "            # Smoothed features\n",
    "            video_df['rel_x_smooth'] = video_df['rel_x'].rolling(7, min_periods=1).mean()\n",
    "            video_df['rel_y_smooth'] = video_df['rel_y'].rolling(7, min_periods=1).mean()\n",
    "            video_df['vx_smooth'] = video_df['vx'].rolling(5, min_periods=1).mean()\n",
    "            video_df['vy_smooth'] = video_df['vy'].rolling(5, min_periods=1).mean()\n",
    "            video_df['speed_smooth'] = video_df['speed'].rolling(5, min_periods=1).mean()\n",
    "            video_df['kinetic_energy'] = 0.5 * video_df['speed_ms']**2\n",
    "            video_df['speed_max5'] = video_df['speed'].rolling(5, min_periods=1).max()\n",
    "            video_df['speed_min5'] = video_df['speed'].rolling(5, min_periods=1).min()\n",
    "            \n",
    "            enhanced_dfs.append(video_df)\n",
    "        \n",
    "        # Combine all videos\n",
    "        if enhanced_dfs:\n",
    "            df_enhanced = pd.concat(enhanced_dfs, ignore_index=True)\n",
    "        else:\n",
    "            print(\"No videos suitable for feature creation\")\n",
    "            return pd.DataFrame(), []\n",
    "        \n",
    "        # Select exactly 69 features\n",
    "        feature_list = [\n",
    "            'rel_x', 'rel_y', 'vx', 'vy', 'vx_ms', 'vy_ms',\n",
    "            'speed', 'speed_ms', 'acceleration', 'direction_change', 'speed_change',\n",
    "            'player_dist', 'trajectory_curvature', 'vx_vy_ratio',\n",
    "            'distance_to_net', 'distance_to_baseline', 'distance_to_sideline',\n",
    "            'frame_number_norm', 'time_in_rally',\n",
    "            'rel_x_smooth', 'rel_y_smooth', 'vx_smooth', 'vy_smooth', 'speed_smooth',\n",
    "            'kinetic_energy', 'speed_max5', 'speed_min5',\n",
    "            'near_net', 'in_corner', 'serve_rally_state',\n",
    "            'court_width_pixels', 'court_height_pixels'\n",
    "        ]\n",
    "        \n",
    "        # Add moving averages and std\n",
    "        for var in base_vars:\n",
    "            feature_list.extend([f'{var}_ma3', f'{var}_ma5', f'{var}_std5'])\n",
    "        \n",
    "        # Ensure exactly 69 features\n",
    "        feature_list = feature_list[:69]\n",
    "        \n",
    "        print(f\"Created {len(feature_list)} features\")\n",
    "        print(f\" Enhanced dataset: {len(df_enhanced)} frames\")\n",
    "        \n",
    "        return df_enhanced, feature_list\n",
    "    \n",
    "    def prepare_sequences(self, df_enhanced, feature_cols):\n",
    "        \"\"\"\n",
    "        Prepare sequences for LSTM prediction\n",
    "        \"\"\"\n",
    "        print(f\" Preparing prediction sequences...\")\n",
    "        \n",
    "        sequences = []\n",
    "        targets = []\n",
    "        metadata = []\n",
    "        \n",
    "        for video_name in df_enhanced['video_name'].unique():\n",
    "            video_data = df_enhanced[df_enhanced['video_name'] == video_name].copy()\n",
    "            \n",
    "            if len(video_data) < self.sequence_length + self.prediction_frames:\n",
    "                continue\n",
    "            \n",
    "            for i in range(self.sequence_length, len(video_data) - self.prediction_frames + 1):\n",
    "                # Input sequence: 12 frames × 69 features\n",
    "                x_seq = video_data.iloc[i-self.sequence_length:i][feature_cols].values\n",
    "                \n",
    "                # Target sequence: 5 frames × 2 coordinates\n",
    "                y_seq = video_data.iloc[i:i+self.prediction_frames][['center_x', 'center_y']].values\n",
    "                \n",
    "                # Skip if any NaN values\n",
    "                if not np.isnan(x_seq).any() and not np.isnan(y_seq).any():\n",
    "                    sequences.append(x_seq)\n",
    "                    targets.append(y_seq)\n",
    "                    \n",
    "                    # Store metadata for this sequence\n",
    "                    metadata.append({\n",
    "                        'video_name': video_name,\n",
    "                        'start_frame': video_data.iloc[i-self.sequence_length]['frame_number'],\n",
    "                        'prediction_frame': video_data.iloc[i]['frame_number'],\n",
    "                        'end_frame': video_data.iloc[i+self.prediction_frames-1]['frame_number']\n",
    "                    })\n",
    "        \n",
    "        if sequences:\n",
    "            X = np.array(sequences)\n",
    "            y = np.array(targets)\n",
    "            \n",
    "            print(f\" Created {len(sequences)} sequences\")\n",
    "            print(f\" Input shape: {X.shape} (batch, seq_len, features)\")\n",
    "            print(f\" Target shape: {y.shape} (batch, pred_frames, coordinates)\")\n",
    "            \n",
    "            return X, y, metadata\n",
    "        else:\n",
    "            print(f\"No valid sequences created\")\n",
    "            return np.array([]), np.array([]), []\n",
    "    \n",
    "    def fit_scaler(self, X):\n",
    "        \"\"\"\n",
    "        Fit the feature scaler\n",
    "        \"\"\"\n",
    "        if len(X) > 0:\n",
    "            # Reshape for normalization: (batch*seq_len, features)\n",
    "            X_reshaped = X.reshape(-1, X.shape[-1])\n",
    "            self.scaler.fit(X_reshaped)\n",
    "            self.is_fitted = True\n",
    "            print(f\"Scaler fitted on {X_reshaped.shape[0]} samples\")\n",
    "        else:\n",
    "            print(f\"No data \")\n",
    "    \n",
    "    def predict_trajectory(self, X_sequence):\n",
    "        \"\"\"\n",
    "        Predict ball trajectory for a single sequence\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            print(\"Scaler not fitted. Using unscaled data.\")\n",
    "            X_scaled = X_sequence\n",
    "        else:\n",
    "            # Scale the input\n",
    "            X_scaled = self.scaler.transform(X_sequence)\n",
    "        \n",
    "        # Add batch dimension and convert to tensor\n",
    "        X_tensor = torch.FloatTensor(X_scaled).unsqueeze(0).to(self.device)  # (1, seq_len, features)\n",
    "        \n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            prediction = self.model(X_tensor)  # (1, pred_frames, 2)\n",
    "            prediction = prediction.cpu().numpy()[0]  # (pred_frames, 2)\n",
    "        \n",
    "        return prediction\n",
    "\n",
    "\n",
    "predictor = TennisLSTMPredictor(model, device)\n",
    "print(\"LSTM Predictor initialized\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Prepare Data for Prediction"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Prepare data for LSTM prediction\n",
    "if len(df_ball) > 0:\n",
    "    ball_valid = df_ball.dropna(subset=['center_x', 'center_y']).copy()\n",
    "    print(f\"Valid ball positions: {len(ball_valid)} / {len(df_ball)}\")\n",
    "    \n",
    "    # Create features\n",
    "    df_enhanced, feature_cols = predictor.create_features(ball_valid, df_players)\n",
    "    \n",
    "    if len(df_enhanced) > 0:\n",
    "        # Prepare sequences\n",
    "        X, y, metadata = predictor.prepare_sequences(df_enhanced, feature_cols)\n",
    "        \n",
    "        if len(X) > 0:\n",
    "            # Fit scaler\n",
    "            predictor.fit_scaler(X)\n",
    "\n",
    "            print(f\"Sequences: {len(X)}\")\n",
    "            print(f\"Videos: {len(set(m['video_name'] for m in metadata))}\")\n",
    "            print(f\"Features per frame: {len(feature_cols)}\")\n",
    "\n",
    "            demo_sequences = []\n",
    "            for i, meta in enumerate(metadata):\n",
    "\n",
    "                frame_span = meta['end_frame'] - meta['start_frame']\n",
    "                if frame_span >= 15:  # At least 15 frames span\n",
    "                    demo_sequences.append((i, meta))\n",
    "            \n",
    "            if demo_sequences:\n",
    "                # Select the first good sequence\n",
    "                demo_idx, demo_meta = demo_sequences[0]\n",
    "\n",
    "                print(f\" Video: {demo_meta['video_name']}\")\n",
    "                print(f\"Frames: {demo_meta['start_frame']} → {demo_meta['end_frame']}\")\n",
    "                print(f\"Prediction starts at frame: {demo_meta['prediction_frame']}\")\n",
    "            else:\n",
    "                print(f\"\\n No suitable sequences found for demonstration\")\n",
    "                demo_idx, demo_meta = 0, metadata[0]\n",
    "        else:\n",
    "            print(f\"No valid sequences created\")\n",
    "    else:\n",
    "        print(f\"Feature creation failed\")\n",
    "else:\n",
    "    print(f\"No ball data available for prediction\")\n",
    "    X, y, metadata = np.array([]), np.array([]), []"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Create Prediction Video Overlay"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class LSTMPredictionVideoOverlay(TennisVideoOverlayCreator):\n",
    "    \"\"\"\n",
    "    Extended video overlay creator with LSTM predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, predictor, court_measurements=None):\n",
    "        super().__init__(court_measurements)\n",
    "        self.predictor = predictor\n",
    "        \n",
    "        # Prediction visualization colors\n",
    "        self.pred_colors = {\n",
    "            'predicted_path': (255, 165, 0),    # Orange\n",
    "            'actual_path': (0, 255, 0),         # Green\n",
    "            'prediction_point': (255, 0, 255),  # Magenta\n",
    "            'error_line': (255, 255, 0),        # Yellow\n",
    "            'confidence_zone': (128, 128, 255)  # Light blue\n",
    "        }\n",
    "    \n",
    "    def draw_prediction_overlay(self, frame, current_frame, ball_history, prediction, actual_future=None):\n",
    "        \"\"\"\n",
    "        Draw LSTM prediction overlay on frame\n",
    "        \"\"\"\n",
    "        overlay = frame.copy()\n",
    "        \n",
    "        #  ball history trail\n",
    "        if len(ball_history) > 1:\n",
    "            history_points = [(int(x), int(y)) for x, y in ball_history if not (np.isnan(x) or np.isnan(y))]\n",
    "            \n",
    "            for i in range(1, len(history_points)):\n",
    "                # Fade older points\n",
    "                alpha = 0.3 + 0.7 * (i / len(history_points))\n",
    "                color = tuple(int(c * alpha) for c in self.colors['ball'])\n",
    "                cv2.line(overlay, history_points[i-1], history_points[i], color, 2)\n",
    "        \n",
    "        #  current ball position\n",
    "        if len(ball_history) > 0:\n",
    "            current_pos = ball_history[-1]\n",
    "            if not (np.isnan(current_pos[0]) or np.isnan(current_pos[1])):\n",
    "                cv2.circle(overlay, (int(current_pos[0]), int(current_pos[1])), 8, self.colors['ball'], -1)\n",
    "                cv2.circle(overlay, (int(current_pos[0]), int(current_pos[1])), 10, (255, 255, 255), 2)\n",
    "        \n",
    "        # predicted trajectory\n",
    "        if len(prediction) > 0:\n",
    "            pred_points = [(int(x), int(y)) for x, y in prediction if not (np.isnan(x) or np.isnan(y))]\n",
    "            \n",
    "            # Connect current position to first prediction\n",
    "            if len(ball_history) > 0 and len(pred_points) > 0:\n",
    "                current_pos = ball_history[-1]\n",
    "                if not (np.isnan(current_pos[0]) or np.isnan(current_pos[1])):\n",
    "                    cv2.line(overlay, (int(current_pos[0]), int(current_pos[1])), \n",
    "                            pred_points[0], self.pred_colors['predicted_path'], 3)\n",
    "            \n",
    "            # prediction path\n",
    "            for i in range(1, len(pred_points)):\n",
    "                cv2.line(overlay, pred_points[i-1], pred_points[i], self.pred_colors['predicted_path'], 3)\n",
    "            \n",
    "            # prediction points\n",
    "            for i, point in enumerate(pred_points):\n",
    "                # Size decreases with distance in future\n",
    "                radius = max(4, 8 - i)\n",
    "                cv2.circle(overlay, point, radius, self.pred_colors['prediction_point'], -1)\n",
    "                cv2.circle(overlay, point, radius + 2, (255, 255, 255), 1)\n",
    "                \n",
    "                # Add frame number\n",
    "                frame_text = f\"+{i+1}\"\n",
    "                cv2.putText(overlay, frame_text, (point[0] + 12, point[1] - 12),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "        \n",
    "        #= future positions if available\n",
    "        if actual_future is not None and len(actual_future) > 0:\n",
    "            actual_points = [(int(x), int(y)) for x, y in actual_future if not (np.isnan(x) or np.isnan(y))]\n",
    "            \n",
    "            # path\n",
    "            for i in range(1, len(actual_points)):\n",
    "                cv2.line(overlay, actual_points[i-1], actual_points[i], self.pred_colors['actual_path'], 2)\n",
    "            \n",
    "            # points\n",
    "            for point in actual_points:\n",
    "                cv2.circle(overlay, point, 4, self.pred_colors['actual_path'], -1)\n",
    "            \n",
    "            #  error lines between predicted and actual\n",
    "            min_len = min(len(pred_points), len(actual_points))\n",
    "            for i in range(min_len):\n",
    "                cv2.line(overlay, pred_points[i], actual_points[i], self.pred_colors['error_line'], 1)\n",
    "        \n",
    "\n",
    "        info_y = 30\n",
    "        cv2.putText(overlay, f\"LSTM Ball Trajectory Prediction\", (10, info_y),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        info_y += 25\n",
    "        cv2.putText(overlay, f\"Current Frame: {current_frame}\", (10, info_y),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        if len(prediction) > 0:\n",
    "            info_y += 20\n",
    "            cv2.putText(overlay, f\"Predicting {len(prediction)} frames ahead (~{len(prediction)/30:.1f}s)\", (10, info_y),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        return overlay\n",
    "    \n",
    "    def add_prediction_info_panel(self, combined_frame, prediction, actual_future, frame_number, errors=None):\n",
    "        \"\"\"\n",
    "        Add prediction analysis panel\n",
    "        \"\"\"\n",
    "        panel_height = 200\n",
    "        panel_width = combined_frame.shape[1]\n",
    "        \n",
    "        # Create info panel\n",
    "        info_panel = np.zeros((panel_height, panel_width, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Title\n",
    "        cv2.putText(info_panel, f\"Frame {frame_number} - LSTM Prediction Analysis\", \n",
    "                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, self.colors['text'], 2)\n",
    "        \n",
    "        # Prediction information\n",
    "        y_offset = 60\n",
    "        if len(prediction) > 0:\n",
    "            cv2.putText(info_panel, \"TRAJECTORY PREDICTION:\", (10, y_offset), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, self.pred_colors['predicted_path'], 2)\n",
    "            y_offset += 25\n",
    "            \n",
    "            # Show predicted positions\n",
    "            for i, (x, y) in enumerate(prediction[:3]):\n",
    "                cv2.putText(info_panel, f\"Frame +{i+1}: ({x:.0f}, {y:.0f})\", \n",
    "                           (20, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors['text'], 1)\n",
    "                y_offset += 18\n",
    "            \n",
    "            if len(prediction) > 3:\n",
    "                cv2.putText(info_panel, f\"... +{len(prediction)} total predictions\", \n",
    "                           (20, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors['text'], 1)\n",
    "        \n",
    "        # Actual vs Predicted comparison\n",
    "        y_offset = 60\n",
    "        x_offset = 400\n",
    "        if actual_future is not None and len(actual_future) > 0:\n",
    "            cv2.putText(info_panel, \"PREDICTION ACCURACY:\", (x_offset, y_offset), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, self.pred_colors['actual_path'], 2)\n",
    "            y_offset += 25\n",
    "            \n",
    "            # Calculate and show errors\n",
    "            if errors is not None and len(errors) > 0:\n",
    "                avg_error = np.mean(errors)\n",
    "                max_error = np.max(errors)\n",
    "                \n",
    "                cv2.putText(info_panel, f\"Average Error: {avg_error:.1f} pixels\", \n",
    "                           (x_offset + 10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors['text'], 1)\n",
    "                y_offset += 18\n",
    "                \n",
    "                cv2.putText(info_panel, f\"Max Error: {max_error:.1f} pixels\", \n",
    "                           (x_offset + 10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors['text'], 1)\n",
    "                y_offset += 18\n",
    "                \n",
    "                # Error in meters (approximate)\n",
    "                pixels_per_meter = 100  # Approximate\n",
    "                cv2.putText(info_panel, f\"Avg Error: {avg_error/pixels_per_meter:.2f} meters\", \n",
    "                           (x_offset + 10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors['text'], 1)\n",
    "        \n",
    "        # Legend\n",
    "        legend_y = 140\n",
    "        cv2.putText(info_panel, \"LEGEND:\", (10, legend_y), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, self.colors['text'], 2)\n",
    "        legend_y += 20\n",
    "        \n",
    "        # Color legend\n",
    "        legends = [\n",
    "            (\"Orange: LSTM Prediction\", self.pred_colors['predicted_path']),\n",
    "            (\"Green: Actual Position\", self.pred_colors['actual_path']),\n",
    "            (\"Yellow: Error\", self.pred_colors['error_line'])\n",
    "        ]\n",
    "        \n",
    "        for i, (text, color) in enumerate(legends):\n",
    "            x_pos = 20 + (i * 200)\n",
    "            cv2.rectangle(info_panel, (x_pos, legend_y-8), (x_pos+15, legend_y+2), color, -1)\n",
    "            cv2.putText(info_panel, text, (x_pos+20, legend_y), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, self.colors['text'], 1)\n",
    "        \n",
    "        return info_panel\n",
    "\n",
    "print(\"LSTM Prediction Video Overlay class created\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Create Prediction Video"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create LSTM prediction video overlay\n",
    "if len(X) > 0 and len(metadata) > 0:\n",
    "    demo_meta = metadata[demo_idx]\n",
    "    demo_video = demo_meta['video_name']\n",
    "    demo_video_path = f\"input_videos/{demo_video}\"\n",
    "    \n",
    "    print(f\"Demo video: {demo_video}\")\n",
    "    print(f\"Prediction sequence: frames {demo_meta['start_frame']} to {demo_meta['end_frame']}\")\n",
    "    \n",
    "    # Check if video exists\n",
    "    if os.path.exists(demo_video_path):\n",
    "        # Get ball data for this video\n",
    "        video_ball_data = df_ball[df_ball['video_name'] == demo_video].copy()\n",
    "        video_player_data = df_players[df_players['video_name'] == demo_video].copy() if len(df_players) > 0 else pd.DataFrame()\n",
    "        \n",
    "        print(f\"   Ball data: {len(video_ball_data)} frames\")\n",
    "        print(f\"   Player data: {len(video_player_data)} detections\")\n",
    "\n",
    "        overlay_creator = LSTMPredictionVideoOverlay(\n",
    "            predictor=predictor,\n",
    "            court_measurements={\n",
    "                'single_line_width': 8.23,\n",
    "                'double_line_width': 10.97,\n",
    "                'half_court_height': 11.88,\n",
    "                'service_line_width': 6.4,\n",
    "                'double_alley_difference': 1.37,\n",
    "                'no_mans_land_height': 5.48\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Create output directory\n",
    "        os.makedirs('prediction_videos', exist_ok=True)\n",
    "        \n",
    "        # Generate output filename\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_filename = f\"prediction_videos/lstm_prediction_{demo_video.replace('.mp4', '')}_{timestamp}.mp4\"\n",
    "        \n",
    "        try:\n",
    "\n",
    "            print(f\"Loading video frames\")\n",
    "            video_frames = read_video(demo_video_path)\n",
    "            \n",
    "            if len(video_frames) == 0:\n",
    "                raise ValueError(\"No frames loaded from video\")\n",
    "            \n",
    "            print(f\"   Loaded {len(video_frames)} frames\")\n",
    "            \n",
    "\n",
    "            fps = 30\n",
    "            frame_width = video_frames[0].shape[1]\n",
    "            frame_height = video_frames[0].shape[0]\n",
    "\n",
    "            mini_court_width = 300\n",
    "            mini_court_height = 150\n",
    "            main_width = frame_width + mini_court_width\n",
    "            main_height = max(frame_height, mini_court_height)\n",
    "            info_panel_height = 200\n",
    "            output_width = main_width\n",
    "            output_height = main_height + info_panel_height\n",
    "            \n",
    "            print(f\"Output dimensions: {output_width}x{output_height}\")\n",
    "\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_filename, fourcc, fps, (output_width, output_height))\n",
    "            \n",
    "            # Process frames for prediction\n",
    "            start_frame = max(0, demo_meta['prediction_frame'] - 30)  # Start 1 second before prediction\n",
    "            end_frame = min(len(video_frames), demo_meta['prediction_frame'] + 90)  # Show 3 seconds of prediction\n",
    "            \n",
    "            print(f\"Processing frames {start_frame} to {end_frame}\")\n",
    "            \n",
    "            # Get prediction sequence\n",
    "            prediction_sequence = X[demo_idx]  # (12, 69)\n",
    "            actual_targets = y[demo_idx]  # (5, 2)\n",
    "            \n",
    "            # Make prediction\n",
    "            predicted_positions = predictor.predict_trajectory(prediction_sequence)\n",
    "            print(f\"Generated prediction: {predicted_positions.shape}\")\n",
    "            \n",
    "            # Create mini court instance\n",
    "            mini_court = MiniCourt(video_frames[start_frame])\n",
    "            \n",
    "            processed_frames = 0\n",
    "            \n",
    "            for frame_idx in range(start_frame, end_frame):\n",
    "                if frame_idx >= len(video_frames):\n",
    "                    break\n",
    "                \n",
    "                current_frame = video_frames[frame_idx].copy()\n",
    "                \n",
    "                # Create output frame\n",
    "                output_frame = np.zeros((output_height, output_width, 3), dtype=np.uint8)\n",
    "                \n",
    "                # Get ball history up to current frame\n",
    "                history_frames = video_ball_data[\n",
    "                    (video_ball_data['frame_number'] >= frame_idx - 12) & \n",
    "                    (video_ball_data['frame_number'] <= frame_idx)\n",
    "                ]\n",
    "                \n",
    "                ball_history = []\n",
    "                for _, row in history_frames.iterrows():\n",
    "                    if not pd.isna(row['center_x']):\n",
    "                        ball_history.append((row['center_x'], row['center_y']))\n",
    "\n",
    "                actual_future = None\n",
    "                if frame_idx >= demo_meta['prediction_frame']:\n",
    "\n",
    "                    future_offset = frame_idx - demo_meta['prediction_frame']\n",
    "                    if future_offset < len(actual_targets):\n",
    "                        actual_future = actual_targets[:future_offset+1]\n",
    "                \n",
    "\n",
    "                prediction_to_show = []\n",
    "                if frame_idx >= demo_meta['prediction_frame']:\n",
    "                    prediction_to_show = predicted_positions\n",
    "                \n",
    "                # Apply prediction overlay\n",
    "                frame_with_prediction = overlay_creator.draw_prediction_overlay(\n",
    "                    current_frame, frame_idx, ball_history, prediction_to_show, actual_future\n",
    "                )\n",
    "                \n",
    "                # Add to output frame\n",
    "                output_frame[0:frame_height, 0:frame_width] = frame_with_prediction\n",
    "                \n",
    "                # Add mini court\n",
    "                mini_court_template = overlay_creator.create_mini_court(mini_court_width, mini_court_height)\n",
    "                \n",
    "                # Draw positions on mini court\n",
    "                if len(ball_history) > 0:\n",
    "                    current_pos = ball_history[-1]\n",
    "                    try:\n",
    "                        mini_pos = mini_court.convert_position_to_mini_court(current_pos)\n",
    "                        mini_x = int(mini_pos[0] * mini_court_width / mini_court.court_drawing_width)\n",
    "                        mini_y = int(mini_pos[1] * mini_court_height / (mini_court.court_drawing_width * 0.5))\n",
    "                        cv2.circle(mini_court_template, (mini_x, mini_y), 4, overlay_creator.colors['ball'], -1)\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                # Add mini court to output\n",
    "                mini_start_x = frame_width\n",
    "                mini_start_y = (main_height - mini_court_height) // 2\n",
    "                output_frame[mini_start_y:mini_start_y + mini_court_height,\n",
    "                           mini_start_x:mini_start_x + mini_court_width] = mini_court_template\n",
    "                \n",
    "                # Add mini court title\n",
    "                cv2.putText(output_frame, \"Mini Court View\",\n",
    "                           (mini_start_x + 10, mini_start_y - 10),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, overlay_creator.colors['text'], 2)\n",
    "                \n",
    "                # Calculate prediction errors\n",
    "                errors = None\n",
    "                if actual_future is not None and len(prediction_to_show) > 0:\n",
    "                    min_len = min(len(actual_future), len(prediction_to_show))\n",
    "                    errors = []\n",
    "                    for i in range(min_len):\n",
    "                        error = np.sqrt((actual_future[i][0] - prediction_to_show[i][0])**2 +\n",
    "                                      (actual_future[i][1] - prediction_to_show[i][1])**2)\n",
    "                        errors.append(error)\n",
    "                \n",
    "                # Add prediction info panel\n",
    "                info_panel = overlay_creator.add_prediction_info_panel(\n",
    "                    output_frame, prediction_to_show, actual_future, frame_idx, errors\n",
    "                )\n",
    "                output_frame[main_height:main_height + info_panel_height, :] = info_panel\n",
    "                \n",
    "                # Write frame\n",
    "                out.write(output_frame)\n",
    "                processed_frames += 1\n",
    "                \n",
    "                # Progress update\n",
    "                if processed_frames % 10 == 0:\n",
    "                    progress = (processed_frames / (end_frame - start_frame)) * 100\n",
    "                    print(f\"Progress: {progress:.1f}% ({processed_frames}/{end_frame - start_frame} frames)\")\n",
    "            \n",
    "            # Cleanup\n",
    "            out.release()\n",
    "\n",
    "            print(f\"Output: {output_filename}\")\n",
    "            print(f\"Processed: {processed_frames} frames\")\n",
    "\n",
    "            \n",
    "            # Try to display a sample frame\n",
    "            try:\n",
    "                cap = cv2.VideoCapture(output_filename)\n",
    "                if cap.isOpened():\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, processed_frames // 2)\n",
    "                    ret, sample_frame = cap.read()\n",
    "                    \n",
    "                    if ret:\n",
    "                        sample_frame_rgb = cv2.cvtColor(sample_frame, cv2.COLOR_BGR2RGB)\n",
    "                        \n",
    "                        plt.figure(figsize=(16, 10))\n",
    "                        plt.imshow(sample_frame_rgb)\n",
    "                        plt.title('LSTM Ball Trajectory Prediction - Sample Frame\\nOrange: Predicted | Green: Actual | Yellow: Error', \n",
    "                                 fontsize=14, fontweight='bold')\n",
    "                        plt.axis('off')\n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "                        \n",
    "                        print(f\"\\nSample frame shows the LSTM prediction overlay in action\")\n",
    "                    \n",
    "                    cap.release()\n",
    "            except Exception as e:\n",
    "                print(f\"Could not display sample frame: {e}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating prediction video: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    else:\n",
    "        print(f\" Demo video not found: {demo_video_path}\")\n",
    "\n",
    "else:\n",
    "    print(f\" No prediction data available for video creation\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Analysis and Evaluation"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "if len(X) > 0 and len(y) > 0:\n",
    "    \n",
    "    # Test predictions on a sample of sequences\n",
    "    sample_size = min(10, len(X))\n",
    "    sample_indices = np.random.choice(len(X), sample_size, replace=False)\n",
    "    \n",
    "    all_errors = []\n",
    "    prediction_analysis = []\n",
    "    \n",
    "    print(f\"Testing LSTM on {sample_size} sequences\")\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        # Get sequence and target\n",
    "        sequence = X[idx]\n",
    "        target = y[idx]\n",
    "        meta = metadata[idx]\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = predictor.predict_trajectory(sequence)\n",
    "        \n",
    "        # Calculate errors\n",
    "        errors = []\n",
    "        for pred_frame in range(len(prediction)):\n",
    "            error = np.sqrt((prediction[pred_frame][0] - target[pred_frame][0])**2 + \n",
    "                           (prediction[pred_frame][1] - target[pred_frame][1])**2)\n",
    "            errors.append(error)\n",
    "        \n",
    "        all_errors.extend(errors)\n",
    "        \n",
    "        # Store analysis\n",
    "        analysis = {\n",
    "            'video': meta['video_name'],\n",
    "            'start_frame': meta['start_frame'],\n",
    "            'prediction_frame': meta['prediction_frame'],\n",
    "            'avg_error_pixels': np.mean(errors),\n",
    "            'max_error_pixels': np.max(errors),\n",
    "            'errors_by_frame': errors\n",
    "        }\n",
    "        prediction_analysis.append(analysis)\n",
    "        \n",
    "        if i < 3:  # Show details for first 3\n",
    "            print(f\"\\n📍 Sequence {i+1} ({meta['video_name']})\")\n",
    "            print(f\"   Frames: {meta['start_frame']} → {meta['prediction_frame']} → {meta['end_frame']}\")\n",
    "            print(f\"   Avg Error: {np.mean(errors):.1f} pixels ({np.mean(errors)/100:.2f}m)\")\n",
    "            print(f\"   Max Error: {np.max(errors):.1f} pixels ({np.max(errors)/100:.2f}m)\")\n",
    "\n",
    "    print(f\"\\nPREDICTION PERFORMANCE:\")\n",
    "    print(f\"   Sequences tested: {sample_size}\")\n",
    "    print(f\"   Average error: {np.mean(all_errors):.1f} pixels ({np.mean(all_errors)/100:.2f} meters)\")\n",
    "    print(f\"   Median error: {np.median(all_errors):.1f} pixels ({np.median(all_errors)/100:.2f} meters)\")\n",
    "    print(f\"   Max error: {np.max(all_errors):.1f} pixels ({np.max(all_errors)/100:.2f} meters)\")\n",
    "    print(f\"   Error std: {np.std(all_errors):.1f} pixels\")\n",
    "\n",
    "    print(f\"\\nError by Prediction Horizon:\")\n",
    "    for frame_ahead in range(5):\n",
    "        frame_errors = []\n",
    "        for analysis in prediction_analysis:\n",
    "            if frame_ahead < len(analysis['errors_by_frame']):\n",
    "                frame_errors.append(analysis['errors_by_frame'][frame_ahead])\n",
    "        \n",
    "        if frame_errors:\n",
    "            avg_error = np.mean(frame_errors)\n",
    "            time_ahead = (frame_ahead + 1) / 30.0  # Convert to seconds\n",
    "            print(f\"   +{frame_ahead+1} frame ({time_ahead:.2f}s): {avg_error:.1f} pixels ({avg_error/100:.2f}m)\")\n",
    "    \n",
    "    # Create error distribution plot\n",
    "    if len(all_errors) > 0:\n",
    "        print(f\"\\n Error distribution plot\")\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Error histogram\n",
    "        ax1.hist(all_errors, bins=20, edgecolor='black', alpha=0.7)\n",
    "        ax1.set_title('LSTM Prediction Error Distribution', fontweight='bold')\n",
    "        ax1.set_xlabel('Error (pixels)')\n",
    "        ax1.set_ylabel('Frequency')\n",
    "        ax1.axvline(np.mean(all_errors), color='red', linestyle='--', \n",
    "                   label=f'Mean: {np.mean(all_errors):.1f}px')\n",
    "        ax1.axvline(np.median(all_errors), color='green', linestyle='--', \n",
    "                   label=f'Median: {np.median(all_errors):.1f}px')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Error by horizon\n",
    "        horizon_errors = [[] for _ in range(5)]\n",
    "        for analysis in prediction_analysis:\n",
    "            for frame_idx, error in enumerate(analysis['errors_by_frame']):\n",
    "                if frame_idx < 5:\n",
    "                    horizon_errors[frame_idx].append(error)\n",
    "        \n",
    "        horizon_means = [np.mean(errors) if errors else 0 for errors in horizon_errors]\n",
    "        horizon_stds = [np.std(errors) if errors else 0 for errors in horizon_errors]\n",
    "        \n",
    "        x_pos = np.arange(1, 6)\n",
    "        ax2.bar(x_pos, horizon_means, yerr=horizon_stds, capsize=5, \n",
    "               edgecolor='black', alpha=0.7)\n",
    "        ax2.set_title('Error by Prediction Horizon', fontweight='bold')\n",
    "        ax2.set_xlabel('Frames Ahead')\n",
    "        ax2.set_ylabel('Average Error (pixels)')\n",
    "        ax2.set_xticks(x_pos)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add time labels\n",
    "        ax2_top = ax2.twiny()\n",
    "        ax2_top.set_xlim(ax2.get_xlim())\n",
    "        ax2_top.set_xticks(x_pos)\n",
    "        ax2_top.set_xticklabels([f'{i/30:.2f}s' for i in x_pos])\n",
    "        ax2_top.set_xlabel('Time Ahead (seconds)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Error analysis complete!\")\n",
    "\n",
    "else:\n",
    "    print(f\"No data available\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ""
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
